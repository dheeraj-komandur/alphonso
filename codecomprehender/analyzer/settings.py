# settings.py

# OpenAI or LLM configuration
CHAT_MODEL = "gpt-4o-mini"
RESEAONING_MODEL = "o4-mini"
CHUNK_TOKEN_LIMIT = 50000
TEMPERATURE = 0.0001

